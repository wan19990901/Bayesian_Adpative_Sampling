"""
Online Direct Preference Optimization (DPO) for Language Models.

This package implements an online version of Direct Preference Optimization (DPO)
for language models, allowing for continuous learning from human preferences.
"""

__version__ = "0.1.0"
